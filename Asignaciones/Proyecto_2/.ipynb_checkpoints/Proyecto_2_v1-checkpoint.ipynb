{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6974964c",
   "metadata": {},
   "source": [
    "# Clasificación de Piso en el Dataset UJIIndoorLoc\n",
    "\n",
    "---\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En este notebook se implementa un flujo completo de procesamiento y análisis para la clasificación del **piso** en un entorno interior utilizando el dataset **UJIIndoorLoc**. Este conjunto de datos contiene mediciones de señales WiFi recopiladas en distintas ubicaciones de un edificio, con información sobre coordenadas, piso, usuario, hora, entre otros.\n",
    "\n",
    "En esta tarea nos enfocaremos en predecir el **piso** en el que se encuentra un dispositivo, considerando únicamente las muestras etiquetadas con valores válidos para dicha variable. Se tratará como un problema de clasificación multiclase (planta baja, primer piso, segundo piso).\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- **Cargar y explorar** el conjunto de datos UJIIndoorLoc.\n",
    "- **Preparar** los datos seleccionando las características relevantes y el target (`FLOOR`).\n",
    "- **Dividir** el dataset en entrenamiento y validación (80/20).\n",
    "- **Entrenar y optimizar** clasificadores basados en seis algoritmos:\n",
    "  - K-Nearest Neighbors (KNN)\n",
    "  - Gaussian Naive Bayes\n",
    "  - Regresión Logística\n",
    "  - Árboles de Decisión\n",
    "  - Support Vector Machines (SVM)\n",
    "  - Random Forest\n",
    "- **Seleccionar hiperparámetros óptimos** para cada modelo utilizando validación cruzada (5-fold), empleando estrategias como **Grid Search**, **Randomized Search**, o **Bayesian Optimization** según el algoritmo.\n",
    "- **Comparar el desempeño** de los modelos sobre el conjunto de validación, usando métricas como *accuracy*, *precision*, *recall*, y *F1-score*.\n",
    "- **Determinar el mejor clasificador** para esta tarea, junto con sus hiperparámetros óptimos.\n",
    "\n",
    "Este ejercicio permite no solo evaluar la capacidad predictiva de distintos algoritmos clásicos de clasificación, sino también desarrollar buenas prácticas en validación de modelos y selección de hiperparámetros en contextos del mundo real.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ad8d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Descripción del Dataset\n",
    "\n",
    "El dataset utilizado en este análisis es el **UJIIndoorLoc Dataset**, ampliamente utilizado para tareas de localización en interiores a partir de señales WiFi. Está disponible públicamente en la UCI Machine Learning Repository y ha sido recopilado en un entorno real de un edificio universitario.\n",
    "\n",
    "Cada muestra corresponde a una observación realizada por un dispositivo móvil, donde se registran las intensidades de señal (RSSI) de más de 500 puntos de acceso WiFi disponibles en el entorno. Además, cada fila contiene información contextual como la ubicación real del dispositivo (coordenadas X e Y), el piso, el edificio, el identificador del usuario, y la marca temporal.\n",
    "\n",
    "El objetivo en esta tarea es predecir el **piso** (`FLOOR`) en el que se encontraba el dispositivo en el momento de la medición, considerando únicamente las características numéricas provenientes de las señales WiFi.\n",
    "\n",
    "### Estructura del dataset\n",
    "\n",
    "- **Número de muestras**: ~20,000\n",
    "- **Número de características**: 520\n",
    "  - 520 columnas con valores de intensidad de señal WiFi (`WAP001` a `WAP520`)\n",
    "- **Variable objetivo**: `FLOOR` (variable categórica con múltiples clases, usualmente entre 0 y 4)\n",
    "\n",
    "### Columnas relevantes\n",
    "\n",
    "- `WAP001`, `WAP002`, ..., `WAP520`: niveles de señal recibida desde cada punto de acceso WiFi (valores entre -104 y 0, o 100 si no se detectó).\n",
    "- `FLOOR`: clase objetivo a predecir (nivel del edificio).\n",
    "- (Otras columnas como `BUILDINGID`, `SPACEID`, `USERID`, `TIMESTAMP`, etc., pueden ser ignoradas o utilizadas en análisis complementarios).\n",
    "\n",
    "### Contexto del problema\n",
    "\n",
    "La localización en interiores es un problema complejo en el que tecnologías como el GPS no funcionan adecuadamente. Los sistemas basados en WiFi han demostrado ser una alternativa efectiva para estimar la ubicación de usuarios en edificios. Poder predecir automáticamente el piso en el que se encuentra una persona puede mejorar aplicaciones de navegación en interiores, accesibilidad, gestión de emergencias y servicios personalizados. Este tipo de problemas es típicamente abordado mediante algoritmos de clasificación multiclase.\n",
    "\n",
    "\n",
    "### Estrategia de evaluación\n",
    "\n",
    "En este análisis seguiremos una metodología rigurosa para garantizar la validez de los resultados:\n",
    "\n",
    "1. **Dataset de entrenamiento**: Se utilizará exclusivamente para el desarrollo, entrenamiento y optimización de hiperparámetros de todos los modelos. Este conjunto será dividido internamente en subconjuntos de entrenamiento y validación (80/20) para la selección de hiperparámetros mediante validación cruzada.\n",
    "\n",
    "2. **Dataset de prueba**: Se reservará únicamente para la **evaluación final** de los modelos ya optimizados. Este conjunto **no debe ser utilizado** durante el proceso de selección de hiperparámetros, ajuste de modelos o toma de decisiones sobre la arquitectura, ya que esto introduciría sesgo y comprometería la capacidad de generalización estimada.\n",
    "\n",
    "3. **Validación cruzada**: Para la optimización de hiperparámetros se empleará validación cruzada 5-fold sobre el conjunto de entrenamiento, lo que permitirá una estimación robusta del rendimiento sin contaminar los datos de prueba.\n",
    "\n",
    "Esta separación estricta entre datos de desarrollo y evaluación final es fundamental para obtener una estimación realista del rendimiento que los modelos tendrían en un escenario de producción con datos completamente nuevos.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b8e4d",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar y explorar el dataset\n",
    "\n",
    "**Instrucciones:**\n",
    "- Descarga el dataset **UJIIndoorLoc** desde la UCI Machine Learning Repository o utiliza la versión proporcionada en el repositorio del curso (por ejemplo: `datasets\\UJIIndoorLoc\\trainingData.csv`).\n",
    "- Carga el dataset utilizando `pandas`.\n",
    "- Muestra las primeras filas del dataset utilizando `df.head()`.\n",
    "- Imprime el número total de muestras (filas) y características (columnas).\n",
    "- Verifica cuántas clases distintas hay en la variable objetivo `FLOOR` y cuántas muestras tiene cada clase (`df['FLOOR'].value_counts()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d27f8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: (19937, 529)\n",
      "\n",
      "Primeras filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7541.2643</td>\n",
       "      <td>4.864921e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7536.6212</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7519.1524</td>\n",
       "      <td>4.864950e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371714095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7524.5704</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7632.1436</td>\n",
       "      <td>4.864982e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1369909710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "0     100     100     100     100     100     100     100     100     100   \n",
       "1     100     100     100     100     100     100     100     100     100   \n",
       "2     100     100     100     100     100     100     100     -97     100   \n",
       "3     100     100     100     100     100     100     100     100     100   \n",
       "4     100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "   WAP010  ...  WAP520  LONGITUDE      LATITUDE  FLOOR  BUILDINGID  SPACEID  \\\n",
       "0     100  ...     100 -7541.2643  4.864921e+06      2           1      106   \n",
       "1     100  ...     100 -7536.6212  4.864934e+06      2           1      106   \n",
       "2     100  ...     100 -7519.1524  4.864950e+06      2           1      103   \n",
       "3     100  ...     100 -7524.5704  4.864934e+06      2           1      102   \n",
       "4     100  ...     100 -7632.1436  4.864982e+06      0           0      122   \n",
       "\n",
       "   RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
       "0                 2       2       23  1371713733  \n",
       "1                 2       2       23  1371713691  \n",
       "2                 2       2       23  1371714095  \n",
       "3                 2       2       23  1371713807  \n",
       "4                 2      11       13  1369909710  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de la variable objetivo FLOOR:\n",
      "FLOOR\n",
      "0    4369\n",
      "1    5002\n",
      "2    4416\n",
      "3    5048\n",
      "4    1102\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías y cargar el dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Ruta al dataset proporcionado\n",
    "train_path = Path('/home/josephjosue/Documents/UIP/Inteligencia Artificial/IA_JOSEPH_LOO/Asignaciones/Proyecto_2/dataset/trainingData.csv')\n",
    "\n",
    "df = pd.read_csv(train_path)\n",
    "print('Dimensiones del dataset:', df.shape)\n",
    "print('\\nPrimeras filas:')\n",
    "display(df.head())\n",
    "\n",
    "print('\\nDistribución de la variable objetivo FLOOR:')\n",
    "print(df['FLOOR'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014f311",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "La exploración inicial es fundamental para entender la naturaleza del problema. Se verifica la dimensión de los datos para confirmar que la carga fue correcta y se revisa la distribución de la variable objetivo (`FLOOR`).\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Volumen de datos:** El dataset cuenta con **19,937 muestras** y **529 columnas**, lo que indica una alta dimensionalidad. Esto sugiere que modelos que manejan bien muchas características (como Random Forest o SVM) podrían tener ventaja.\n",
    "- **Desbalance de clases:** Al observar el conteo de `FLOOR`, notamos que los pisos 0, 1, 2 y 3 tienen entre 4,000 y 5,000 muestras cada uno, pero el **piso 4 es una clase minoritaria** con solo ~1,100 muestras. Esto es crucial, ya que el modelo podría tener dificultades para predecir el piso 4 si no se utiliza una estrategia de validación estratificada (`stratify=y`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f0bed",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 2: Preparar los datos\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "- Elimina las columnas que no son relevantes para la tarea de clasificación del piso:\n",
    "  - `LONGITUDE`, `LATITUDE`, `SPACEID`, `RELATIVEPOSITION`, `USERID`, `PHONEID`, `TIMESTAMP`\n",
    "- Conserva únicamente:\n",
    "  - Las columnas `WAP001` a `WAP520` como características (RSSI de puntos de acceso WiFi).\n",
    "  - La columna `FLOOR` como variable objetivo.\n",
    "- Verifica si existen valores atípicos o valores inválidos en las señales WiFi (por ejemplo: valores constantes como 100 o -110 que suelen indicar ausencia de señal).\n",
    "- Separa el conjunto de datos en:\n",
    "  - `X`: matriz de características (todas las columnas `WAP`)\n",
    "  - `y`: vector objetivo (`FLOOR`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0eec3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de columnas WAP: 520\n",
      "Valores atípicos (100) antes del reemplazo: 10008477\n",
      "Valores -110 presentes: 0\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar columnas relevantes (WAPs y FLOOR) y eliminar las irrelevantes\n",
    "cols_to_drop = ['LONGITUDE', 'LATITUDE', 'SPACEID', 'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
    "df_model = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Columnas de características (WAP001 a WAP520)\n",
    "wap_cols = [col for col in df_model.columns if col.startswith('WAP')]\n",
    "X_raw = df_model[wap_cols].copy()\n",
    "y = df_model['FLOOR'].copy()\n",
    "\n",
    "print('Número de columnas WAP:', len(wap_cols))\n",
    "print('Valores atípicos (100) antes del reemplazo:', (X_raw == 100).sum().sum())\n",
    "print('Valores -110 presentes:', (X_raw == -110).sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874938a",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "Se eliminaron columnas de contexto como `USERID`, `PHONEID` y `TIMESTAMP`. La razón es evitar que el modelo aprenda sesgos específicos (ej. \"el usuario X siempre está en el piso Y\") en lugar de aprender la relación real entre la señal WiFi y la ubicación. Queremos un modelo generalizable a cualquier usuario.\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Valores atípicos (100):** Se detectaron más de **10 millones** de valores iguales a `100`. Dado que la matriz es de ~10.5 millones de celdas en total (19k filas x 520 columnas), esto confirma que la matriz es \"dispersa\" (sparse): la gran mayoría de los puntos de acceso no son detectados en cada escaneo.\n",
    "- **Limpieza:** No se encontraron valores `-110` (otro código de error común), por lo que el único \"ruido\" principal a tratar es el valor 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a6c39",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Paso 3: Preprocesamiento de las señales WiFi\n",
    "\n",
    "**Contexto:**\n",
    "\n",
    "Las columnas `WAP001` a `WAP520` representan la intensidad de la señal (RSSI) recibida desde distintos puntos de acceso WiFi. Los valores típicos de RSSI están en una escala negativa, donde:\n",
    "\n",
    "- Valores cercanos a **0 dBm** indican señal fuerte.\n",
    "- Valores cercanos a **-100 dBm** indican señal débil o casi ausente.\n",
    "- Un valor de **100** en este dataset representa una señal **no detectada**, es decir, el punto de acceso no fue visto por el dispositivo en ese instante.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "- Para facilitar el procesamiento y tratar la ausencia de señal de forma coherente, se recomienda mapear todos los valores **100** a **-100**, que semánticamente representa *ausencia de señal detectable*.\n",
    "- Esto unifica el rango de valores y evita que 100 (un valor artificial) afecte negativamente la escala de los algoritmos.\n",
    "\n",
    "**Pasos sugeridos:**\n",
    "\n",
    "- Reemplaza todos los valores `100` por `-100` en las columnas `WAP001` a `WAP520`:\n",
    "  ```python\n",
    "  X[X == 100] = -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fa6fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores 100 después del reemplazo: 0\n",
      "Rango de valores tras preprocesamiento: (np.int64(-104), np.int64(0))\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar valores 100 por -100 para representar ausencia de señal\n",
    "X = X_raw.replace(100, -100)\n",
    "\n",
    "print('Valores 100 después del reemplazo:', (X == 100).sum().sum())\n",
    "print('Rango de valores tras preprocesamiento:', (X.min().min(), X.max().max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b465c0",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "El valor `100` es un indicador simbólico de \"no señal\", pero numéricamente es un valor positivo alto. Los algoritmos de ML interpretan esto como una señal **muy fuerte** (mayor que -30 dBm), lo cual es opuesto a la realidad.\n",
    "Se reemplazó por `-100` para ubicarlo en el extremo inferior de la escala de decibelios.\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Consistencia Matemática:** El rango de valores ahora va de **-104 a 0**. Esto crea una escala continua y lógica donde \"mayor valor\" significa estrictamente \"mayor intensidad de señal\", facilitando el aprendizaje de algoritmos basados en distancia (KNN) o gradiente (Regresión Logística)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80383336",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Paso 4: Entrenamiento y optimización de hiperparámetros\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Entrenar y comparar distintos clasificadores para predecir correctamente el piso (`FLOOR`) y encontrar los mejores hiperparámetros para cada uno mediante validación cruzada.\n",
    "\n",
    "**Clasificadores a evaluar:**\n",
    "\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Gaussian Naive Bayes\n",
    "- Regresión Logística\n",
    "- Árboles de Decisión\n",
    "- Support Vector Machines (SVM)\n",
    "- Random Forest\n",
    "\n",
    "**Procedimiento:**\n",
    "\n",
    "1. Divide el dataset en conjunto de **entrenamiento** (80%) y **validación** (20%) usando `train_test_split` con `stratify=y`.\n",
    "2. Para cada clasificador:\n",
    "   - Define el espacio de búsqueda de hiperparámetros.\n",
    "   - Usa **validación cruzada 5-fold** sobre el conjunto de entrenamiento para seleccionar los mejores hiperparámetros.\n",
    "   - Emplea una estrategia de búsqueda adecuada:\n",
    "     - **GridSearchCV**: búsqueda exhaustiva (ideal para espacios pequeños).\n",
    "     - **RandomizedSearchCV**: búsqueda aleatoria (más eficiente con espacios amplios).\n",
    "     - **Bayesian Optimization** (opcional): para búsquedas más inteligentes, usando librerías como `optuna` o `skopt`.\n",
    "3. Guarda el mejor modelo encontrado para cada clasificador con su configuración óptima.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87cd1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear conjuntos de entrenamiento y validación\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "best_models = {}\n",
    "best_params = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "850e98ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros KNN: {'model__n_neighbors': 3, 'model__weights': 'distance'}\n",
      "Mejor accuracy de validación: 0.9873974703403452\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y optimizar KNN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "knn_params = {\n",
    "    'model__n_neighbors': [3, 5, 7],\n",
    "    'model__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(\n",
    "    knn_pipe,\n",
    "    knn_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_knn.fit(X_train, y_train)\n",
    "best_models['KNN'] = grid_knn.best_estimator_\n",
    "best_params['KNN'] = grid_knn.best_params_\n",
    "\n",
    "print('Mejores hiperparámetros KNN:', grid_knn.best_params_)\n",
    "print('Mejor accuracy de validación:', grid_knn.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d272e1",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "KNN basa su predicción en la similitud de las huellas de señal. Se probaron distintos valores de vecinos (`n_neighbors`) y pesos. La elección de `StandardScaler` en el pipeline es crítica aquí, ya que KNN es muy sensible a la escala de las distancias, y estandarizar asegura que todos los WAPs contribuyan equitativamente.\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Rendimiento:** El modelo obtuvo un accuracy de validación muy alto (**~98.7%**).\n",
    "- **Configuración ganadora:** `n_neighbors=3` con `weights='distance'`.\n",
    "  - El hecho de que prefiera **3 vecinos** (un número bajo) indica que la localización es muy específica: la señal cambia rápidamente al moverse y solo las muestras muy cercanas son representativas.\n",
    "  - El peso por **distancia** implica que las muestras más cercanas (señales más parecidas) tienen mayor voto que las lejanas, lo cual tiene sentido físico en la propagación de ondas de radio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34cc6ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros GaussianNB: {'model__var_smoothing': np.float64(1e-07)}\n",
      "Mejor accuracy de validación: 0.5575273151929979\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y optimizar Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Búsqueda sencilla sobre var_smoothing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gnb_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # mantener dispersión sin centrar en 0\n",
    "    ('model', GaussianNB())\n",
    "])\n",
    "\n",
    "gnb_params = {\n",
    "    'model__var_smoothing': np.logspace(-11, -7, 5)\n",
    "}\n",
    "\n",
    "grid_gnb = GridSearchCV(\n",
    "    gnb_pipe,\n",
    "    gnb_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_gnb.fit(X_train, y_train)\n",
    "best_models['GaussianNB'] = grid_gnb.best_estimator_\n",
    "best_params['GaussianNB'] = grid_gnb.best_params_\n",
    "\n",
    "print('Mejores hiperparámetros GaussianNB:', grid_gnb.best_params_)\n",
    "print('Mejor accuracy de validación:', grid_gnb.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3196cdc",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "Se incluyó este modelo como una línea base probabilística simple. Se optimizó el parámetro `var_smoothing` para ayudar a la estabilidad numérica. Naive Bayes asume que la intensidad de cada WAP es independiente de los demás dado el piso.\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Rendimiento:** El accuracy fue bajo (**~55.7%**), siendo el peor de todos los modelos probados.\n",
    "- **Causa del bajo desempeño:** La suposición de \"independencia\" es falsa en este contexto. En la realidad, si un punto de acceso tiene señal fuerte, es muy probable que los puntos de acceso vecinos también la tengan. Esta fuerte correlación entre las características (WAPs) viola la hipótesis central del algoritmo, impidiendo que aprenda correctamente la estructura de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7bc6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros Regresión Logística: {'model__C': 1.0, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}\n",
      "Mejor accuracy de validación: 0.9931658886198738\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y optimizar Regresión Logística\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    # Se eliminó 'multi_class=\"auto\"' para corregir el warning\n",
    "    ('model', LogisticRegression(max_iter=500, n_jobs=-1))\n",
    "])\n",
    "\n",
    "logreg_params = {\n",
    "    'model__C': [0.1, 1.0, 10.0],\n",
    "    'model__penalty': ['l2'],\n",
    "    'model__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "grid_logreg = GridSearchCV(\n",
    "    logreg_pipe,\n",
    "    logreg_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_logreg.fit(X_train, y_train)\n",
    "best_models['LogisticRegression'] = grid_logreg.best_estimator_\n",
    "best_params['LogisticRegression'] = grid_logreg.best_params_\n",
    "\n",
    "print('Mejores hiperparámetros Regresión Logística:', grid_logreg.best_params_)\n",
    "print('Mejor accuracy de validación:', grid_logreg.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492f98d",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "Se evaluó un modelo lineal para verificar si las fronteras de decisión entre pisos son simples. Se utilizó el solver `lbfgs` por su eficiencia en problemas multiclase y penalización `l2` para controlar el sobreajuste en un espacio de 520 dimensiones.\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Rendimiento:** Sorprendentemente alto (**~99.3%**), superando a KNN.\n",
    "- **Interpretación:** Esto sugiere que, tras el preprocesamiento (cambiar 100 por -100), los datos son **linealmente separables** en el hiperespacio. El modelo logró encontrar hiperplanos que dividen claramente los pisos basándose en la combinación lineal de las intensidades de señal, siendo una opción muy eficiente y precisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1fca347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros Árbol de Decisión: {'model__criterion': 'gini', 'model__max_depth': None, 'model__min_samples_split': 2}\n",
      "Mejor accuracy de validación: 0.965703402467927\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y optimizar Árbol de Decisión\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cart_params = {\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [10, 20, None],\n",
    "    'model__min_samples_split': [2, 10]\n",
    "}\n",
    "\n",
    "cart_pipe = Pipeline([\n",
    "    ('model', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "grid_cart = GridSearchCV(\n",
    "    cart_pipe,\n",
    "    cart_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_cart.fit(X_train, y_train)\n",
    "best_models['DecisionTree'] = grid_cart.best_estimator_\n",
    "best_params['DecisionTree'] = grid_cart.best_params_\n",
    "\n",
    "print('Mejores hiperparámetros Árbol de Decisión:', grid_cart.best_params_)\n",
    "print('Mejor accuracy de validación:', grid_cart.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a8ab9b",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "Los árboles de decisión permiten capturar relaciones no lineales mediante reglas del tipo \"Si WAP1 < -80 y WAP2 > -50, entonces Piso 1\". Se exploró la profundidad máxima y el criterio de división para evitar árboles demasiado complejos que memoricen los datos.\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Rendimiento:** Bueno (**~96.5%**), pero inferior a KNN y Regresión Logística.\n",
    "- **Configuración:** Eligió `max_depth=None`, lo que significa que el árbol creció completamente hasta clasificar puramente las hojas. Aunque tiene un buen accuracy en validación, un árbol sin límite de profundidad suele ser propenso a sufrir varianza (pequeños cambios en los datos cambian la estructura del árbol), lo que explica por qué rinde un poco menos que los modelos más robustos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cdbe3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros SVM: {'model__C': 10, 'model__gamma': 'auto', 'model__kernel': 'rbf'}\n",
      "Mejor accuracy de validación: 0.99216261620323\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y optimizar Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "svm_params = {\n",
    "    'model__C': [1, 10],\n",
    "    'model__kernel': ['rbf'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    svm_pipe,\n",
    "    svm_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_svm.fit(X_train, y_train)\n",
    "best_models['SVM'] = grid_svm.best_estimator_\n",
    "best_params['SVM'] = grid_svm.best_params_\n",
    "\n",
    "print('Mejores hiperparámetros SVM:', grid_svm.best_params_)\n",
    "print('Mejor accuracy de validación:', grid_svm.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbf43c",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "SVM busca el hiperplano óptimo que maximiza el margen entre clases. Dado que los datos pueden no ser linealmente separables en su forma original, se probó el kernel `rbf` (Radial Basis Function) para proyectar los datos a una dimensión superior donde sí lo sean.\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Rendimiento:** Excelente (**~99.2%**), prácticamente empatado con la Regresión Logística.\n",
    "- **Configuración:** `C=10` y kernel `rbf`. Un valor de `C` alto indica que el modelo priorizó clasificar correctamente todos los puntos de entrenamiento (margen duro) sobre tener un margen más suave. Aunque el resultado es muy bueno, el costo computacional de entrenar SVM con kernel no lineal en casi 20,000 muestras es significativamente mayor que en los otros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38458a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros Random Forest: {'model__max_depth': None, 'model__max_features': 'sqrt', 'model__n_estimators': 200}\n",
      "Mejor accuracy de validación: 0.9964888709327026\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y optimizar Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "rf_params = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [None, 20],\n",
    "    'model__max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    rf_pipe,\n",
    "    rf_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_models['RandomForest'] = grid_rf.best_estimator_\n",
    "best_params['RandomForest'] = grid_rf.best_params_\n",
    "\n",
    "print('Mejores hiperparámetros Random Forest:', grid_rf.best_params_)\n",
    "print('Mejor accuracy de validación:', grid_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfecdeaa",
   "metadata": {},
   "source": [
    "### Justificación\n",
    "Random Forest combina cientos de árboles de decisión para reducir la varianza y el riesgo de sobreajuste del árbol individual. Se probó con 100 y 200 estimadores para ver si aumentar la cantidad de árboles mejoraba la estabilidad.\n",
    "\n",
    "### Análisis de Resultados\n",
    "- **Rendimiento:** El mejor de todos (**~99.6%** en validación).\n",
    "- **Configuración:** `n_estimators=200` y `max_features='sqrt'`.\n",
    "- **Interpretación:** Al promediar 200 árboles, el modelo logra cancelar los errores individuales y el ruido inherente a las señales WiFi fluctuantes. Es el clasificador más robusto, capturando la complejidad no lineal del entorno sin caer en el sobreajuste que podría afectar a un solo árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de7a7c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 5: Crear una tabla resumen de los mejores modelos\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "Después de entrenar y optimizar todos los clasificadores, debes construir una **tabla resumen en formato Markdown** que incluya:\n",
    "\n",
    "- El **nombre del modelo**\n",
    "- Los **hiperparámetros óptimos** encontrados mediante validación cruzada\n",
    "\n",
    "### Requisitos:\n",
    "\n",
    "- La tabla debe estar escrita en formato **Markdown**.\n",
    "- Cada fila debe corresponder a uno de los modelos evaluados.\n",
    "- Incluye solo los **mejores hiperparámetros** para cada modelo, es decir, aquellos que produjeron el mayor rendimiento en la validación cruzada (accuracy o F1-score).\n",
    "- No incluyas aún las métricas de evaluación (eso se hará en el siguiente paso).\n",
    "\n",
    "### Ejemplo de formato:\n",
    "\n",
    "\n",
    "| Modelo                 | Hiperparámetros óptimos                            |\n",
    "|------------------------|----------------------------------------------------|\n",
    "| KNN                    | n_neighbors=5, weights='distance'                  |\n",
    "| Gaussian Naive Bayes   | var_smoothing=1e-9 (por defecto)                   |\n",
    "| Regresión Logística    | C=1.0, solver='lbfgs'                              |\n",
    "| Árbol de Decisión      | max_depth=10, criterion='entropy'                  |\n",
    "| SVM                    | C=10, kernel='rbf', gamma='scale'                  |\n",
    "| Random Forest          | n_estimators=200, max_depth=20                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431b048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b2d5a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Modelo             | Hiperparámetros óptimos                             |\n",
      "|:-------------------|:----------------------------------------------------|\n",
      "| DecisionTree       | criterion=gini, max_depth=None, min_samples_split=2 |\n",
      "| GaussianNB         | var_smoothing=1e-07                                 |\n",
      "| KNN                | n_neighbors=3, weights=distance                     |\n",
      "| LogisticRegression | C=1.0, penalty=l2, solver=lbfgs                     |\n",
      "| RandomForest       | max_depth=None, max_features=sqrt, n_estimators=200 |\n",
      "| SVM                | C=10, gamma=auto, kernel=rbf                        |\n"
     ]
    }
   ],
   "source": [
    "#Resumen en tabla Markdown de los mejores hiperparámetros\n",
    "import pandas as pd\n",
    "\n",
    "summary_rows = []\n",
    "for model_name, params in best_params.items():\n",
    "    readable = ', '.join(f\"{k.split('__')[-1]}={v}\" for k, v in params.items())\n",
    "    summary_rows.append({'Modelo': model_name, 'Hiperparámetros óptimos': readable})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values('Modelo')\n",
    "\n",
    "print(summary_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8c70b",
   "metadata": {},
   "source": [
    "| Modelo             | Hiperparámetros óptimos                             |\n",
    "|:-------------------|:----------------------------------------------------|\n",
    "| DecisionTree       | criterion=gini, max_depth=None, min_samples_split=2 |\n",
    "| GaussianNB         | var_smoothing=1e-07                                 |\n",
    "| KNN                | n_neighbors=3, weights=distance                     |\n",
    "| LogisticRegression | C=1.0, penalty=l2, solver=lbfgs                     |\n",
    "| RandomForest       | max_depth=None, max_features=sqrt, n_estimators=200 |\n",
    "| SVM                | C=10, gamma=auto, kernel=rbf                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397af15",
   "metadata": {},
   "source": [
    "### Análisis de la Configuración Óptima\n",
    "La tabla resume la \"mejor versión\" de cada algoritmo. Destaca que:\n",
    "- **SVM** requirió un kernel `rbf` (radial basis function), lo que confirma que las relaciones en los datos son complejas y no lineales.\n",
    "- **Decision Tree** no requirió limitar la profundidad (`max_depth=None`), lo que implica que el árbol creció completamente para ajustarse a los datos de entrenamiento; esto suele ser propenso al overfitting, pero Random Forest corrige esto mediante el ensamble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8951e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 6: Preparar los datos finales para evaluación\n",
    "\n",
    "**Objetivo:**\n",
    "Cargar el dataset de entrenamiento y prueba, limpiar las columnas innecesarias, ajustar los valores de señal, y dejar los datos listos para probar los modelos entrenados.\n",
    "\n",
    "**Instrucciones:**\n",
    "Implementa una función que:\n",
    "- Cargue los archivos `trainingData.csv` y `validationData.csv`\n",
    "- Elimine las columnas irrelevantes (`LONGITUDE`, `LATITUDE`, `SPACEID`, `RELATIVEPOSITION`, `USERID`, `PHONEID`, `TIMESTAMP`)\n",
    "- Reemplace los valores `100` por `-100` en las columnas `WAP001` a `WAP520`\n",
    "- Separe las características (`X`) y la variable objetivo (`FLOOR`)\n",
    "- Devuelva los conjuntos `X_train`, `X_test`, `y_train`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2519692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones entrenamiento: (19937, 520)\n",
      "Dimensiones prueba: (1111, 520)\n"
     ]
    }
   ],
   "source": [
    "# Función para preparar datos finales de entrenamiento y prueba\n",
    "from typing import Tuple\n",
    "\n",
    "def load_and_prepare_data() -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    train_path = Path('/home/josephjosue/Documents/UIP/Inteligencia Artificial/IA_JOSEPH_LOO/Asignaciones/Proyecto_2/dataset/trainingData.csv')\n",
    "    test_path = Path('/home/josephjosue/Documents/UIP/Inteligencia Artificial/IA_JOSEPH_LOO/Asignaciones/Proyecto_2/dataset/validationData.csv')\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    cols_to_drop = ['LONGITUDE', 'LATITUDE', 'SPACEID', 'RELATIVEPOSITION', 'USERID', 'PHONEID', 'TIMESTAMP']\n",
    "    train_df = train_df.drop(columns=cols_to_drop)\n",
    "    test_df = test_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    wap_cols = [col for col in train_df.columns if col.startswith('WAP')]\n",
    "\n",
    "    X_train_full = train_df[wap_cols].replace(100, -100)\n",
    "    y_train_full = train_df['FLOOR']\n",
    "\n",
    "    X_test_full = test_df[wap_cols].replace(100, -100)\n",
    "    y_test_full = test_df['FLOOR']\n",
    "\n",
    "    return X_train_full, X_test_full, y_train_full, y_test_full\n",
    "\n",
    "# Preparar los datos finales\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = load_and_prepare_data()\n",
    "\n",
    "print('Dimensiones entrenamiento:', X_train_full.shape)\n",
    "print('Dimensiones prueba:', X_test_full.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1611e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Paso 7: Evaluar modelos optimizados en el conjunto de prueba\n",
    "\n",
    "**Objetivo:**\n",
    "Evaluar el rendimiento real de los modelos optimizados usando el conjunto de prueba (`X_test`, `y_test`), previamente separado. Cada modelo debe ser entrenado nuevamente sobre **todo el conjunto de entrenamiento** (`X_train`, `y_train`) con sus mejores hiperparámetros, y luego probado en `X_test`.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "1. Para cada modelo:\n",
    "   - Usa los **hiperparámetros óptimos** encontrados en el Paso 4.\n",
    "   - Entrena el modelo con `X_train` y `y_train`.\n",
    "   - Calcula y guarda:\n",
    "     - `Accuracy`\n",
    "     - `Precision` (macro)\n",
    "     - `Recall` (macro)\n",
    "     - `F1-score` (macro)\n",
    "     - `AUC` (promedio one-vs-rest si es multiclase)\n",
    "     - Tiempo de entrenamiento (`train_time`)\n",
    "     - Tiempo de predicción (`test_time`)\n",
    "2. Muestra todos los resultados en una **tabla comparativa**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10347fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_macro</th>\n",
       "      <th>Recall_macro</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>AUC_macro</th>\n",
       "      <th>train_time_s</th>\n",
       "      <th>test_time_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.911791</td>\n",
       "      <td>0.920280</td>\n",
       "      <td>0.886258</td>\n",
       "      <td>0.899047</td>\n",
       "      <td>0.987003</td>\n",
       "      <td>4.139536</td>\n",
       "      <td>0.094134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.885689</td>\n",
       "      <td>0.865869</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.876255</td>\n",
       "      <td>0.973110</td>\n",
       "      <td>6.491721</td>\n",
       "      <td>0.011324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.814581</td>\n",
       "      <td>0.831712</td>\n",
       "      <td>0.815868</td>\n",
       "      <td>0.818992</td>\n",
       "      <td>0.904229</td>\n",
       "      <td>0.872698</td>\n",
       "      <td>0.609050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.812781</td>\n",
       "      <td>0.819311</td>\n",
       "      <td>0.800071</td>\n",
       "      <td>0.806209</td>\n",
       "      <td>0.876567</td>\n",
       "      <td>1.256583</td>\n",
       "      <td>0.006530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>0.812374</td>\n",
       "      <td>0.788334</td>\n",
       "      <td>0.786633</td>\n",
       "      <td>0.960829</td>\n",
       "      <td>191.011419</td>\n",
       "      <td>1.851737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.453645</td>\n",
       "      <td>0.468592</td>\n",
       "      <td>0.570678</td>\n",
       "      <td>0.442186</td>\n",
       "      <td>0.769796</td>\n",
       "      <td>0.901410</td>\n",
       "      <td>0.088139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  Accuracy  Precision_macro  Recall_macro  F1_macro  \\\n",
       "5        RandomForest  0.911791         0.920280      0.886258  0.899047   \n",
       "2  LogisticRegression  0.885689         0.865869      0.890995  0.876255   \n",
       "0                 KNN  0.814581         0.831712      0.815868  0.818992   \n",
       "3        DecisionTree  0.812781         0.819311      0.800071  0.806209   \n",
       "4                 SVM  0.792079         0.812374      0.788334  0.786633   \n",
       "1          GaussianNB  0.453645         0.468592      0.570678  0.442186   \n",
       "\n",
       "   AUC_macro  train_time_s  test_time_s  \n",
       "5   0.987003      4.139536     0.094134  \n",
       "2   0.973110      6.491721     0.011324  \n",
       "0   0.904229      0.872698     0.609050  \n",
       "3   0.876567      1.256583     0.006530  \n",
       "4   0.960829    191.011419     1.851737  \n",
       "1   0.769796      0.901410     0.088139  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluar los modelos optimizados en el conjunto de prueba\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.base import clone\n",
    "import time\n",
    "\n",
    "results = []\n",
    "classes = np.unique(y_train_full)\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    start_train = time.perf_counter()\n",
    "    fitted = clone(model).fit(X_train_full, y_train_full)\n",
    "    train_time = time.perf_counter() - start_train\n",
    "\n",
    "    start_test = time.perf_counter()\n",
    "    y_pred = fitted.predict(X_test_full)\n",
    "    test_time = time.perf_counter() - start_test\n",
    "\n",
    "    # Obtener probabilidades para AUC si están disponibles\n",
    "    y_score = None\n",
    "    if hasattr(fitted, 'predict_proba'):\n",
    "        y_score = fitted.predict_proba(X_test_full)\n",
    "    elif hasattr(fitted, 'decision_function'):\n",
    "        y_score = fitted.decision_function(X_test_full)\n",
    "\n",
    "    if y_score is not None:\n",
    "        y_test_bin = label_binarize(y_test_full, classes=classes)\n",
    "        auc = roc_auc_score(y_test_bin, y_score, average='macro', multi_class='ovr')\n",
    "    else:\n",
    "        auc = np.nan\n",
    "\n",
    "    results.append({\n",
    "        'Modelo': name,\n",
    "        'Accuracy': accuracy_score(y_test_full, y_pred),\n",
    "        'Precision_macro': precision_score(y_test_full, y_pred, average='macro', zero_division=0),\n",
    "        'Recall_macro': recall_score(y_test_full, y_pred, average='macro', zero_division=0),\n",
    "        'F1_macro': f1_score(y_test_full, y_pred, average='macro', zero_division=0),\n",
    "        'AUC_macro': auc,\n",
    "        'train_time_s': train_time,\n",
    "        'test_time_s': test_time\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b96c7",
   "metadata": {},
   "source": [
    "### Justificación de la Evaluación Final\n",
    "Se evaluaron los modelos en el conjunto `test` (validationData.csv), que nunca fue visto durante el entrenamiento ni la selección de hiperparámetros. Esto simula el rendimiento real en producción. Se midieron también los tiempos de ejecución para evaluar la viabilidad de implementación en tiempo real.\n",
    "\n",
    "### Análisis Comparativo de Resultados\n",
    "1. **Mejor Modelo (Random Forest):**\n",
    "   - **Accuracy: 91.18%**. Es el ganador indiscutible. Su capacidad para manejar características irrelevantes (puntos de acceso apagados) y correlaciones no lineales lo hace ideal.\n",
    "   - **Estabilidad:** Muestra un equilibrio excelente entre Precision y Recall.\n",
    "\n",
    "2. **La Alternativa Eficiente (Regresión Logística):**\n",
    "   - **Accuracy: 88.57%**. Aunque es 2.5% menos preciso que el Random Forest, su tiempo de predicción es **8 veces más rápido** (0.01s vs 0.09s). Si el sistema se fuera a implementar en un microcontrolador simple, este sería el modelo a elegir.\n",
    "\n",
    "3. **Modelos a Descartar:**\n",
    "   - **Gaussian Naive Bayes (45%):** Completamente ineficaz para este tipo de datos correlacionados.\n",
    "   - **SVM (79%):** A pesar de ser un algoritmo potente, fue **extremadamente lento** en entrenamiento (191 segundos) y tuvo un rendimiento inferior a modelos más simples como KNN o Regresión Logística en este escenario específico.\n",
    "\n",
    "4. **Conclusión Técnica:**\n",
    "   El problema de clasificación de pisos se resuelve mejor con métodos de ensamble (**Random Forest**) debido a la naturaleza ruidosa y de alta dimensión de las señales RSSI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf813b",
   "metadata": {},
   "source": [
    "---\n",
    "## Paso 8: Selección y justificación del mejor modelo\n",
    "\n",
    "**Objetivo:**\n",
    "Analizar los resultados obtenidos en el paso anterior y **emitir una conclusión razonada** sobre cuál de los modelos evaluados es el más adecuado para la tarea de predicción del piso en el dataset UJIIndoorLoc.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "- Observa la tabla comparativa del Paso 7 y responde:\n",
    "  - ¿Qué modelo obtuvo el **mejor rendimiento general** en términos de **accuracy** y **F1-score**?\n",
    "  - ¿Qué tan consistente fue su rendimiento en **precision** y **recall**?\n",
    "  - ¿Tiene un **tiempo de entrenamiento o inferencia** excesivamente alto?\n",
    "  - ¿El modelo necesita **normalización**, muchos recursos o ajustes delicados?\n",
    "- Basándote en estos aspectos, **elige un solo modelo** como el mejor clasificador para esta tarea.\n",
    "- **Justifica tu elección** considerando tanto el desempeño como la eficiencia y facilidad de implementación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a61042",
   "metadata": {},
   "source": [
    "La comparación en el conjunto de prueba muestra que el modelo con mayor **accuracy** y **F1 macro** es el que se posiciona como mejor opción. Considerando también que su `precision` y `recall` son consistentes y que los tiempos de entrenamiento/inferencia son razonables frente al resto, el modelo seleccionado es el que encabeza la tabla anterior (generalmente SVM o Random Forest en este problema). Este modelo ofrece un equilibrio adecuado entre desempeño y eficiencia para la clasificación de pisos en el dataset UJIIndoorLoc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574f4a5",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Análisis de Resultados\n",
    "\n",
    "Al observar la tabla comparativa generada en el paso anterior, podemos extraer las siguientes conclusiones sobre las métricas clave:\n",
    "\n",
    "- **Mejor Rendimiento General (Accuracy y F1-Score):**\n",
    "  El modelo **Random Forest** obtuvo el mejor desempeño global, logrando un **Accuracy del 91.18%** y un **F1-Score (macro) del 89.90%**. Esto indica que es el clasificador que mejor generaliza los patrones de señal WiFi para determinar el piso correcto.\n",
    "\n",
    "- **Consistencia (Precision vs Recall):**\n",
    "  Random Forest mostró una gran solidez, con una Precision macro de **92.03%** y un Recall macro de **88.63%**. La cercanía entre ambos valores sugiere que el modelo es equilibrado: no solo acierta cuando predice, sino que es capaz de recuperar la mayoría de las instancias de cada clase sin sesgarse excesivamente.\n",
    "\n",
    "- **Eficiencia (Tiempos de Entrenamiento e Inferencia):**\n",
    "  - **Entrenamiento:** Random Forest entrenó en **~4.14 segundos**, un tiempo muy competitivo. En contraste, **SVM** fue extremadamente ineficiente, tomando **~191 segundos** (casi 3 minutos) debido a la complejidad del kernel RBF en este volumen de datos.\n",
    "  - **Inferencia:** Aunque la Regresión Logística fue la más rápida en predecir (0.01s), el tiempo de inferencia de Random Forest (**0.09s** para todo el set de prueba) es despreciable y perfectamente apto para aplicaciones en tiempo real.\n",
    "\n",
    "- **Complejidad y Ajustes:**\n",
    "  A diferencia de SVM, que requirió un ajuste costoso y estandarización estricta para rendir decentemente (y aun así quedó por debajo en accuracy con un 79.2%), Random Forest demostró ser robusto \"out-of-the-box\", manejando bien la alta dimensionalidad y el ruido inherente a las señales RSSI sin requerir tanta manipulación.\n",
    "\n",
    "### 2. Conclusión y Selección del Modelo\n",
    "\n",
    "> **Modelo Seleccionado:** **Random Forest**\n",
    "\n",
    "### 3. Justificación de la Elección\n",
    "\n",
    "Se elige **Random Forest** como el modelo definitivo para este proyecto por las siguientes razones:\n",
    "\n",
    "1.  **Superioridad en Métricas:** Fue el único modelo que superó la barrera del 90% de exactitud en el conjunto de prueba, superando a la Regresión Logística (88.5%) y dejando muy atrás a SVM (79.2%) y Naive Bayes (45.3%).\n",
    "2.  **Robustez:** Su naturaleza de ensamble (200 árboles) le permite reducir la varianza y manejar eficazmente los valores atípicos y las características irrelevantes (puntos de acceso sin señal), lo cual es crítico en este dataset.\n",
    "3.  **Eficiencia Práctica:** Ofrece el mejor equilibrio costo-beneficio. Aunque no es el más rápido de todos, su velocidad es suficiente para producción, y su precisión extra justifica el costo computacional frente a modelos lineales más simples.\n",
    "\n",
    "Por lo tanto, **Random Forest** es la solución más confiable y precisa para la tarea de localización de pisos en el edificio de la UJI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f47b37a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Rúbrica de Evaluación\n",
    "\n",
    "| Paso | Descripción | Puntuación |\n",
    "|------|-------------|------------|\n",
    "| 1 | Cargar y explorar el dataset | 5 |\n",
    "| 2 | Preparar los datos | 5 |\n",
    "| 3 | Preprocesamiento de las señales WiFi | 10 |\n",
    "| 4 | Entrenamiento y optimización de hiperparámetros | 40 |\n",
    "| 5 | Crear una tabla resumen de los mejores modelos | 5 |\n",
    "| 6 | Preparar los datos finales para evaluación | 5 |\n",
    "| 7 | Evaluar modelos optimizados en el conjunto de prueba | 10 |\n",
    "| 8 | Selección y justificación del mejor modelo | 20 |\n",
    "| **Total** | | **100** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40599c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyda-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
