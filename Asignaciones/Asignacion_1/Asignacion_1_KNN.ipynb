{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774c713",
   "metadata": {},
   "source": [
    "## Descripción del dataset: Pima Indians Diabetes\n",
    "\n",
    "El **Pima Indians Diabetes Dataset** es un conjunto de datos clásico en Machine Learning y bioestadística, recopilado por el *National Institute of Diabetes and Digestive and Kidney Diseases*.  \n",
    "Su propósito es **predecir la aparición de diabetes tipo 2** en mujeres de origen **pima** (una población indígena del sur de Arizona, EE.UU.), a partir de diversas variables clínicas y demográficas.\n",
    "\n",
    "### Características principales:\n",
    "- **Número de registros:** 392 (en esta versión limpia, el original tenía 768).  \n",
    "- **Número de atributos (features):** 8 variables predictoras + 1 variable objetivo.  \n",
    "- **Población:** Mujeres de al menos 21 años de edad de la etnia Pima.  \n",
    "- **Tarea principal:** Clasificación binaria → determinar si una paciente tiene diabetes (`Outcome = 1`) o no (`Outcome = 0`).\n",
    "\n",
    "### Variables:\n",
    "1. **Pregnancies** → Número de embarazos.  \n",
    "2. **Glucose** → Concentración de glucosa en plasma después de 2 horas en una prueba de tolerancia a la glucosa.  \n",
    "3. **BloodPressure** → Presión arterial diastólica (mm Hg).  \n",
    "4. **SkinThickness** → Espesor del pliegue cutáneo del tríceps (mm).  \n",
    "5. **Insulin** → Nivel sérico de insulina (mu U/ml).  \n",
    "6. **BMI** → Índice de masa corporal (peso en kg / altura² en m²).  \n",
    "7. **DiabetesPedigreeFunction** → Probabilidad de diabetes basada en antecedentes familiares.  \n",
    "8. **Age** → Edad en años.  \n",
    "9. **Outcome** → Variable objetivo:  \n",
    "   - `0` = No tiene diabetes  \n",
    "   - `1` = Tiene diabetes  \n",
    "\n",
    "### Relevancia:\n",
    "Este dataset es ampliamente utilizado en cursos de **Inteligencia Artificial y Machine Learning** para enseñar:\n",
    "- Procesamiento y limpieza de datos biomédicos.  \n",
    "- Métodos de clasificación supervisada (KNN, regresión logística, Random Forest, SVM, redes neuronales, etc.).  \n",
    "- Importancia de la normalización y estandarización en algoritmos basados en distancias.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ef96",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar la base de datos  \n",
    "Cargamos el CSV en un `DataFrame` de `pandas`. Si tu archivo no se llama exactamente `cleaned_dataset.csv`, ajusta la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17934010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
      "0            0      129             110              46      130  67.1   \n",
      "1            0      180              78              63       14  59.4   \n",
      "2            3      123             100              35      240  57.3   \n",
      "3            1       88              30              42       99  55.0   \n",
      "4            0      162              76              56      100  53.2   \n",
      "\n",
      "   Diabetes Pedigree Function  Age  Outcome  \n",
      "0                       0.319   26        1  \n",
      "1                       2.420   25        1  \n",
      "2                       0.880   22        0  \n",
      "3                       0.496   26        1  \n",
      "4                       0.759   25        1  \n",
      "Filas: 392, Columnas: 9\n"
     ]
    }
   ],
   "source": [
    "#codigo aqui\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('dataset/cleaned_dataset.csv')\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(df.head())\n",
    "\n",
    "# Imprimir la cantidad de filas y columnas\n",
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b7ef2",
   "metadata": {},
   "source": [
    "## Paso 2: Crear subconjuntos con 20 datos de **entrenamiento** y 20 de **testeo**\n",
    "Seleccionaremos 40 muestras: 20 para entrenar y 20 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cce560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo aqui\n",
    "def cargar_y_dividir_dataset(df):\n",
    "    # Seleccionar las primeras 20 muestras para entrenamiento\n",
    "    train = df.iloc[:20]\n",
    "    # Seleccionar las siguientes 20 muestras para prueba\n",
    "    test = df.iloc[20:40]\n",
    "    # Separar características y etiquetas\n",
    "    X_train = train.drop('Outcome', axis=1).values\n",
    "    y_train = train['Outcome'].values\n",
    "    X_test = test.drop('Outcome', axis=1).values\n",
    "    y_test = test['Outcome'].values\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = cargar_y_dividir_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1e8d1",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la función de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente fórmula matemática para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu función con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Embarazos | Glucosa | Presión Arterial | Grosor Piel | Insulina | IMC  | Función Hereditaria | Edad | Resultado |\n",
    "|-----------|---------|------------------|-------------|----------|------|---------------------|------|-----------|\n",
    "|     1     |   106   |        70        |      28     |   135    | 34.2 |        0.142        |  22  |     0     |\n",
    "|     2     |   102   |        86        |      36     |   120    | 45.5 |        0.127        |  23  |     1     |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu función sea el mismo.\n",
    "- La función debe imprimir el resultado del cálculo de la distancia euclidiana con los datos presentados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa56bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia euclidiana (función): 26.280986\n",
      "Diferencias: [-1.00e+00  4.00e+00 -1.60e+01 -8.00e+00  1.50e+01 -1.13e+01  1.50e-02\n",
      " -1.00e+00]\n",
      "Cuadrados: [1.0000e+00 1.6000e+01 2.5600e+02 6.4000e+01 2.2500e+02 1.2769e+02\n",
      " 2.2500e-04 1.0000e+00]\n",
      "Suma de cuadrados: 690.690225\n",
      "Distancia euclidiana (paso a paso): 26.280986\n",
      "Verificación: OK - ambos métodos coinciden\n"
     ]
    }
   ],
   "source": [
    "# Implementación de la distancia euclidiana\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"Calcula la distancia euclidiana entre dos vectores (listas o arrays).\n",
    "    Lanza ValueError si las dimensiones no coinciden.\"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    y = np.array(y, dtype=float)\n",
    "    if x.shape != y.shape:\n",
    "        raise ValueError(\"Los vectores deben tener la misma longitud\")\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Vectores de ejemplo (sin la columna Outcome)\n",
    "v1 = [1, 106, 70, 28, 135, 34.2, 0.142, 22]\n",
    "v2 = [2, 102, 86, 36, 120, 45.5, 0.127, 23]\n",
    "\n",
    "# Cálculo usando la función\n",
    "dist = euclidean_distance(v1, v2)\n",
    "print(f\"Distancia euclidiana (función): {dist:.6f}\")\n",
    "\n",
    "# Cálculo paso a paso para verificar (suma de cuadrados y raíz)\n",
    "diff = np.array(v1, dtype=float) - np.array(v2, dtype=float)\n",
    "sq = diff ** 2\n",
    "sum_sq = np.sum(sq)\n",
    "manual = np.sqrt(sum_sq)\n",
    "print(\"Diferencias:\", diff)\n",
    "print(\"Cuadrados:\", sq)\n",
    "print(f\"Suma de cuadrados: {sum_sq:.6f}\")\n",
    "print(f\"Distancia euclidiana (paso a paso): {manual:.6f}\")\n",
    "\n",
    "assert np.isclose(dist, manual), \"La verificación falló: valores no coinciden\"\n",
    "print(\"Verificación: OK - ambos métodos coinciden\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73bbcc",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN básico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu función de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos más cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu función a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Resultado` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación KNN básico (k=3)\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_predict(x_train, y_train, x_test_point, k=3):\n",
    "    \"\"\"Predice la etiqueta de x_test_point usando KNN (mayoría simple).\n",
    "    Devuelve (predicción, distancias_de_los_k_vecinos).\"\"\"\n",
    "    # calcular distancias a todos los ejemplos de entrenamiento\n",
    "    dists = np.array([euclidean_distance(x_test_point, x) for x in x_train])\n",
    "    # índices de los k vecinos más cercanos\n",
    "    idx = np.argsort(dists)[:k]\n",
    "    nearest_labels = [y_train[i] for i in idx]\n",
    "    vote = Counter(nearest_labels)\n",
    "    # resolver empates: seleccionar la etiqueta con mayor cuenta; si hay empate, elegir la menor etiqueta\n",
    "    max_count = max(vote.values())\n",
    "    candidates = [label for label, cnt in vote.items() if cnt == max_count]\n",
    "    prediction = min(candidates)\n",
    "    return int(prediction), dists[idx]\n",
    "\n",
    "# Usar las primeras 10 muestras de entrenamiento y las primeras 10 de test según Paso 2\n",
    "X_tr10 = X_train[:10]\n",
    "y_tr10 = y_train[:10]\n",
    "X_te10 = X_test[:10]\n",
    "y_te10 = y_test[:10]\n",
    "\n",
    "# Imprimir tabla comparativa (índice, actual, predicho, distancias de los k vecinos)\n",
    "print(f\"{'Idx':<4} {'Actual':<6} {'Predicted':<9} {'Distances (k=3)'}\")\n",
    "correct = 0\n",
    "for i, x in enumerate(X_te10):\n",
    "    pred, neigh_dists = knn_predict(X_tr10, y_tr10, x, k=3)\n",
    "    print(f\"{i:<4} {y_te10[i]:<6} {pred:<9} {np.round(neigh_dists,4)}\")\n",
    "    if pred == int(y_te10[i]):\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(X_te10)\n",
    "print(f\"\n",
    "\n",
    "Accuracy sobre las 10 muestras de test: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f7f05",
   "metadata": {},
   "source": [
    "## Paso 5: Usar toda la data con separación 80% entrenamiento / 20% testeo  \n",
    "\n",
    "### Pasos:\n",
    "1. Cargar todo el dataset.  \n",
    "2. Separar variables (X) y etiquetas (y).  \n",
    "3. Aplicar `train_test_split` con 80% para entrenamiento y 20% para testeo.  \n",
    "4. Mantener la proporción de clases usando estratificación.  \n",
    "5. Guardar los conjuntos de datos para usarlos en KNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb071d8",
   "metadata": {},
   "source": [
    "## Paso 6: Entrenar un KNN con los datos sin escalar (crudos) y calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Definir el valor de **k = 3** y el metodo **Euclidiano**.  \n",
    "2. Entrenar el modelo KNN con los datos crudos (sin normalizar/estandarizar).  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** comparando predicciones con etiquetas reales.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82664821",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **normalización Min-Max** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos normalizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32694423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6519b",
   "metadata": {},
   "source": [
    "## Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **estandarización Z-score** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos estandarizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946086",
   "metadata": {},
   "source": [
    "## Paso 10/11: Tabla comparativa de accuracies  \n",
    "\n",
    "### Pasos:\n",
    "1. Reunir los resultados de accuracy de cada experimento:  \n",
    "   - KNN sin escalar (80/20).  \n",
    "   - KNN normalizado (80/20).  \n",
    "   - KNN estandarizado (80/20).  \n",
    "2. Crear una tabla con los resultados.  \n",
    "3. Comparar el desempeño de cada método.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#codigo aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cafd7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de reflexión y aplicación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bf383",
   "metadata": {},
   "source": [
    "1. ¿Por qué es importante normalizar o estandarizar los datos antes de usar KNN?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ee450",
   "metadata": {},
   "source": [
    "Responda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393faba",
   "metadata": {},
   "source": [
    "2. ¿Qué diferencias observaste en el accuracy entre los datos crudos, normalizados y estandarizados?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6273f",
   "metadata": {},
   "source": [
    "Respinda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2743a4d",
   "metadata": {},
   "source": [
    "3. Si aumentamos el valor de **k** (número de vecinos), ¿cómo crees que cambiaría el rendimiento del modelo?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817198b3",
   "metadata": {},
   "source": [
    "Responda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a02e07",
   "metadata": {},
   "source": [
    "4. ¿Qué ventaja tiene implementar KNN manualmente antes de usar scikit-learn?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b32f9",
   "metadata": {},
   "source": [
    "respuesta aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53e18",
   "metadata": {},
   "source": [
    "5. ¿Qué limitaciones presenta KNN cuando se aplica a conjuntos de datos grandes o con muchas dimensiones?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76827e64",
   "metadata": {},
   "source": [
    "respuesta aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707edf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c9c",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación: Práctica KNN\n",
    "\n",
    "| Criterio | Descripción | Puntaje Máximo |\n",
    "|----------|-------------|----------------|\n",
    "| **1. Carga y exploración del dataset** | Carga correcta del archivo CSV, explicación de las variables y verificación de datos. | 15 pts |\n",
    "| **2. Implementación manual de KNN** | Código propio para calcular distancias euclidianas, selección de vecinos y votación mayoritaria. | 20 pts |\n",
    "| **3. Predicción individual (ejemplo aleatorio)** | Explicación clara del proceso paso a paso para un ejemplo de test. | 10 pts |\n",
    "| **4. Uso de scikit-learn (KNN)** | Entrenamiento y evaluación con `train_test_split`, comparación con el método manual. | 15 pts |\n",
    "| **5. Normalización y estandarización** | Aplicación correcta de Min-Max y Z-score, con cálculo de accuracy en cada caso. | 20 pts |\n",
    "| **6. Tabla comparativa de accuracies** | Presentación clara de los resultados y comparación entre métodos. | 10 pts |\n",
    "| **7. Reflexión y preguntas finales** | Respuestas a las preguntas de análisis planteadas (profundidad y claridad). | 10 pts |\n",
    "\n",
    "**Total: 100 pts**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyda-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
