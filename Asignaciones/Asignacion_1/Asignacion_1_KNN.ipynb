{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774c713",
   "metadata": {},
   "source": [
    "## Descripci\u00f3n del dataset: Pima Indians Diabetes\n",
    "\n",
    "El **Pima Indians Diabetes Dataset** es un conjunto de datos cl\u00e1sico en Machine Learning y bioestad\u00edstica, recopilado por el *National Institute of Diabetes and Digestive and Kidney Diseases*.  \n",
    "Su prop\u00f3sito es **predecir la aparici\u00f3n de diabetes tipo 2** en mujeres de origen **pima** (una poblaci\u00f3n ind\u00edgena del sur de Arizona, EE.UU.), a partir de diversas variables cl\u00ednicas y demogr\u00e1ficas.\n",
    "\n",
    "### Caracter\u00edsticas principales:\n",
    "- **N\u00famero de registros:** 392 (en esta versi\u00f3n limpia, el original ten\u00eda 768).  \n",
    "- **N\u00famero de atributos (features):** 8 variables predictoras + 1 variable objetivo.  \n",
    "- **Poblaci\u00f3n:** Mujeres de al menos 21 a\u00f1os de edad de la etnia Pima.  \n",
    "- **Tarea principal:** Clasificaci\u00f3n binaria \u2192 determinar si una paciente tiene diabetes (`Outcome = 1`) o no (`Outcome = 0`).\n",
    "\n",
    "### Variables:\n",
    "1. **Pregnancies** \u2192 N\u00famero de embarazos.  \n",
    "2. **Glucose** \u2192 Concentraci\u00f3n de glucosa en plasma despu\u00e9s de 2 horas en una prueba de tolerancia a la glucosa.  \n",
    "3. **BloodPressure** \u2192 Presi\u00f3n arterial diast\u00f3lica (mm Hg).  \n",
    "4. **SkinThickness** \u2192 Espesor del pliegue cut\u00e1neo del tr\u00edceps (mm).  \n",
    "5. **Insulin** \u2192 Nivel s\u00e9rico de insulina (mu U/ml).  \n",
    "6. **BMI** \u2192 \u00cdndice de masa corporal (peso en kg / altura\u00b2 en m\u00b2).  \n",
    "7. **DiabetesPedigreeFunction** \u2192 Probabilidad de diabetes basada en antecedentes familiares.  \n",
    "8. **Age** \u2192 Edad en a\u00f1os.  \n",
    "9. **Outcome** \u2192 Variable objetivo:  \n",
    "   - `0` = No tiene diabetes  \n",
    "   - `1` = Tiene diabetes  \n",
    "\n",
    "### Relevancia:\n",
    "Este dataset es ampliamente utilizado en cursos de **Inteligencia Artificial y Machine Learning** para ense\u00f1ar:\n",
    "- Procesamiento y limpieza de datos biom\u00e9dicos.  \n",
    "- M\u00e9todos de clasificaci\u00f3n supervisada (KNN, regresi\u00f3n log\u00edstica, Random Forest, SVM, redes neuronales, etc.).  \n",
    "- Importancia de la normalizaci\u00f3n y estandarizaci\u00f3n en algoritmos basados en distancias.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ef96",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar la base de datos  \n",
    "Cargamos el CSV en un `DataFrame` de `pandas`. Si tu archivo no se llama exactamente `cleaned_dataset.csv`, ajusta la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17934010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el dataset\n",
    "ruta_csv = 'dataset/cleaned_dataset.csv'\n",
    "df = pd.read_csv(ruta_csv)\n",
    "\n",
    "# Mostrar informaci\u00f3n b\u00e1sica\n",
    "df.head(), df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b7ef2",
   "metadata": {},
   "source": [
    "## Paso 2: Crear subconjuntos con 20 datos de **entrenamiento** y 20 de **testeo**\n",
    "Seleccionaremos 40 muestras: 20 para entrenar y 20 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar 40 muestras aleatorias y dividir en 20/20\n",
    "df_40 = df.sample(n=40, random_state=42)\n",
    "X_small = df_40.drop('Outcome', axis=1)\n",
    "y_small = df_40['Outcome']\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "    X_small, y_small, train_size=20, test_size=20, random_state=42, stratify=y_small\n",
    ")\n",
    "\n",
    "X_train_small.shape, X_test_small.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1e8d1",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la funci\u00f3n de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una funci\u00f3n en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente f\u00f3rmula matem\u00e1tica para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu funci\u00f3n con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Embarazos | Glucosa | Presi\u00f3n Arterial | Grosor Piel | Insulina | IMC  | Funci\u00f3n Hereditaria | Edad | Resultado |\n",
    "|-----------|---------|------------------|-------------|----------|------|---------------------|------|-----------|\n",
    "|     1     |   106   |        70        |      28     |   135    | 34.2 |        0.142        |  22  |     0     |\n",
    "|     2     |   102   |        86        |      36     |   120    | 45.5 |        0.127        |  23  |     1     |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu funci\u00f3n sea el mismo.\n",
    "- La funci\u00f3n debe imprimir el resultado del c\u00e1lculo de la distancia euclidiana con los datos presentados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa56bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia_euclidiana(v1, v2):\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    return np.sqrt(np.sum((v1 - v2) ** 2))\n",
    "\n",
    "# Ejemplo r\u00e1pido\n",
    "ejemplo = distancia_euclidiana(X_train_small.iloc[0], X_test_small.iloc[0])\n",
    "ejemplo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73bbcc",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN b\u00e1sico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una funci\u00f3n que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu funci\u00f3n de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos m\u00e1s cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu funci\u00f3n a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Resultado` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente c\u00f3digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def knn_manual(X_train, y_train, X_test, k=3):\n",
    "    predicciones = []\n",
    "    for _, x_test in X_test.iterrows():\n",
    "        # Calcular distancias a todos los puntos de entrenamiento\n",
    "        distancias = [\n",
    "            (distancia_euclidiana(x_test, x_train), y)\n",
    "            for x_train, y in zip(X_train.values, y_train)\n",
    "        ]\n",
    "        # Ordenar por distancia y tomar los k vecinos\n",
    "        vecinos = sorted(distancias, key=lambda t: t[0])[:k]\n",
    "        etiquetas = [etq for _, etq in vecinos]\n",
    "        # Votaci\u00f3n mayoritaria\n",
    "        pred = Counter(etiquetas).most_common(1)[0][0]\n",
    "        predicciones.append(pred)\n",
    "    return np.array(predicciones)\n",
    "\n",
    "pred_small = knn_manual(X_train_small, y_train_small, X_test_small, k=3)\n",
    "acc_small = accuracy_score(y_test_small, pred_small)\n",
    "acc_small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f7f05",
   "metadata": {},
   "source": [
    "## Paso 5: Usar toda la data con separaci\u00f3n 80% entrenamiento / 20% testeo  \n",
    "\n",
    "### Pasos:\n",
    "1. Cargar todo el dataset.  \n",
    "2. Separar variables (X) y etiquetas (y).  \n",
    "3. Aplicar `train_test_split` con 80% para entrenamiento y 20% para testeo.  \n",
    "4. Mantener la proporci\u00f3n de clases usando estratificaci\u00f3n.  \n",
    "5. Guardar los conjuntos de datos para usarlos en KNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables y etiqueta\n",
    "y = df['Outcome']\n",
    "X = df.drop('Outcome', axis=1)\n",
    "\n",
    "# Divisi\u00f3n 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb071d8",
   "metadata": {},
   "source": [
    "## Paso 6: Entrenar un KNN con los datos sin escalar (crudos) y calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Definir el valor de **k = 3** y el metodo **Euclidiano**.  \n",
    "2. Entrenar el modelo KNN con los datos crudos (sin normalizar/estandarizar).  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** comparando predicciones con etiquetas reales.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN sin escalar\n",
    "knn_crudo = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_crudo.fit(X_train, y_train)\n",
    "\n",
    "pred_crudo = knn_crudo.predict(X_test)\n",
    "acc_crudo = accuracy_score(y_test, pred_crudo)\n",
    "acc_crudo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82664821",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **normalizaci\u00f3n Min-Max** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos normalizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32694423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizaci\u00f3n Min-Max\n",
    "minmax = MinMaxScaler()\n",
    "X_train_norm = minmax.fit_transform(X_train)\n",
    "X_test_norm = minmax.transform(X_test)\n",
    "\n",
    "knn_norm = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_norm.fit(X_train_norm, y_train)\n",
    "\n",
    "pred_norm = knn_norm.predict(X_test_norm)\n",
    "acc_norm = accuracy_score(y_test, pred_norm)\n",
    "acc_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6519b",
   "metadata": {},
   "source": [
    "## Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **estandarizaci\u00f3n Z-score** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos estandarizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10afcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizaci\u00f3n Z-score\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "knn_std = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_std.fit(X_train_std, y_train)\n",
    "\n",
    "pred_std = knn_std.predict(X_test_std)\n",
    "acc_std = accuracy_score(y_test, pred_std)\n",
    "acc_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946086",
   "metadata": {},
   "source": [
    "## Paso 10/11: Tabla comparativa de accuracies  \n",
    "\n",
    "### Pasos:\n",
    "1. Reunir los resultados de accuracy de cada experimento:  \n",
    "   - KNN sin escalar (80/20).  \n",
    "   - KNN normalizado (80/20).  \n",
    "   - KNN estandarizado (80/20).  \n",
    "2. Crear una tabla con los resultados.  \n",
    "3. Comparar el desempe\u00f1o de cada m\u00e9todo.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla comparativa de accuracies\n",
    "import pandas as pd\n",
    "resultados = pd.DataFrame({\n",
    "    'Experimento': ['KNN crudo', 'KNN Min-Max', 'KNN Z-score'],\n",
    "    'Accuracy': [acc_crudo, acc_norm, acc_std]\n",
    "})\n",
    "resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cafd7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de reflexi\u00f3n y aplicaci\u00f3n\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bf383",
   "metadata": {},
   "source": [
    "1. \u00bfPor qu\u00e9 es importante normalizar o estandarizar los datos antes de usar KNN?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ee450",
   "metadata": {},
   "source": [
    "Responda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393faba",
   "metadata": {},
   "source": [
    "2. \u00bfQu\u00e9 diferencias observaste en el accuracy entre los datos crudos, normalizados y estandarizados?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6273f",
   "metadata": {},
   "source": [
    "Respinda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2743a4d",
   "metadata": {},
   "source": [
    "3. Si aumentamos el valor de **k** (n\u00famero de vecinos), \u00bfc\u00f3mo crees que cambiar\u00eda el rendimiento del modelo?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817198b3",
   "metadata": {},
   "source": [
    "Responda aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a02e07",
   "metadata": {},
   "source": [
    "4. \u00bfQu\u00e9 ventaja tiene implementar KNN manualmente antes de usar scikit-learn?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b32f9",
   "metadata": {},
   "source": [
    "respuesta aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53e18",
   "metadata": {},
   "source": [
    "5. \u00bfQu\u00e9 limitaciones presenta KNN cuando se aplica a conjuntos de datos grandes o con muchas dimensiones?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76827e64",
   "metadata": {},
   "source": [
    "respuesta aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707edf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c9c",
   "metadata": {},
   "source": [
    "## R\u00fabrica de evaluaci\u00f3n: Pr\u00e1ctica KNN\n",
    "\n",
    "| Criterio | Descripci\u00f3n | Puntaje M\u00e1ximo |\n",
    "|----------|-------------|----------------|\n",
    "| **1. Carga y exploraci\u00f3n del dataset** | Carga correcta del archivo CSV, explicaci\u00f3n de las variables y verificaci\u00f3n de datos. | 15 pts |\n",
    "| **2. Implementaci\u00f3n manual de KNN** | C\u00f3digo propio para calcular distancias euclidianas, selecci\u00f3n de vecinos y votaci\u00f3n mayoritaria. | 20 pts |\n",
    "| **3. Predicci\u00f3n individual (ejemplo aleatorio)** | Explicaci\u00f3n clara del proceso paso a paso para un ejemplo de test. | 10 pts |\n",
    "| **4. Uso de scikit-learn (KNN)** | Entrenamiento y evaluaci\u00f3n con `train_test_split`, comparaci\u00f3n con el m\u00e9todo manual. | 15 pts |\n",
    "| **5. Normalizaci\u00f3n y estandarizaci\u00f3n** | Aplicaci\u00f3n correcta de Min-Max y Z-score, con c\u00e1lculo de accuracy en cada caso. | 20 pts |\n",
    "| **6. Tabla comparativa de accuracies** | Presentaci\u00f3n clara de los resultados y comparaci\u00f3n entre m\u00e9todos. | 10 pts |\n",
    "| **7. Reflexi\u00f3n y preguntas finales** | Respuestas a las preguntas de an\u00e1lisis planteadas (profundidad y claridad). | 10 pts |\n",
    "\n",
    "**Total: 100 pts**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}