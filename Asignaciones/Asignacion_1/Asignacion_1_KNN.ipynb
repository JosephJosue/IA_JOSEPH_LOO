{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774c713",
   "metadata": {},
   "source": [
    "## Descripción del dataset: Pima Indians Diabetes\n",
    "\n",
    "El **Pima Indians Diabetes Dataset** es un conjunto de datos clásico en Machine Learning y bioestadística, recopilado por el *National Institute of Diabetes and Digestive and Kidney Diseases*.  \n",
    "Su propósito es **predecir la aparición de diabetes tipo 2** en mujeres de origen **pima** (una población indígena del sur de Arizona, EE.UU.), a partir de diversas variables clínicas y demográficas.\n",
    "\n",
    "### Características principales:\n",
    "- **Número de registros:** 392 (en esta versión limpia, el original tenía 768).  \n",
    "- **Número de atributos (features):** 8 variables predictoras + 1 variable objetivo.  \n",
    "- **Población:** Mujeres de al menos 21 años de edad de la etnia Pima.  \n",
    "- **Tarea principal:** Clasificación binaria → determinar si una paciente tiene diabetes (`Outcome = 1`) o no (`Outcome = 0`).\n",
    "\n",
    "### Variables:\n",
    "1. **Pregnancies** → Número de embarazos.  \n",
    "2. **Glucose** → Concentración de glucosa en plasma después de 2 horas en una prueba de tolerancia a la glucosa.  \n",
    "3. **BloodPressure** → Presión arterial diastólica (mm Hg).  \n",
    "4. **SkinThickness** → Espesor del pliegue cutáneo del tríceps (mm).  \n",
    "5. **Insulin** → Nivel sérico de insulina (mu U/ml).  \n",
    "6. **BMI** → Índice de masa corporal (peso en kg / altura² en m²).  \n",
    "7. **DiabetesPedigreeFunction** → Probabilidad de diabetes basada en antecedentes familiares.  \n",
    "8. **Age** → Edad en años.  \n",
    "9. **Outcome** → Variable objetivo:  \n",
    "   - `0` = No tiene diabetes  \n",
    "   - `1` = Tiene diabetes  \n",
    "\n",
    "### Relevancia:\n",
    "Este dataset es ampliamente utilizado en cursos de **Inteligencia Artificial y Machine Learning** para enseñar:\n",
    "- Procesamiento y limpieza de datos biomédicos.  \n",
    "- Métodos de clasificación supervisada (KNN, regresión logística, Random Forest, SVM, redes neuronales, etc.).  \n",
    "- Importancia de la normalización y estandarización en algoritmos basados en distancias.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ef96",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar la base de datos  \n",
    "Cargamos el CSV en un `DataFrame` de `pandas`. Si tu archivo no se llama exactamente `cleaned_dataset.csv`, ajusta la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17934010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
       " 0            0      129             110              46      130  67.1   \n",
       " 1            0      180              78              63       14  59.4   \n",
       " 2            3      123             100              35      240  57.3   \n",
       " 3            1       88              30              42       99  55.0   \n",
       " 4            0      162              76              56      100  53.2   \n",
       " \n",
       "    Diabetes Pedigree Function  Age  Outcome  \n",
       " 0                       0.319   26        1  \n",
       " 1                       2.420   25        1  \n",
       " 2                       0.880   22        0  \n",
       " 3                       0.496   26        1  \n",
       " 4                       0.759   25        1  ,\n",
       " (392, 9))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el dataset\n",
    "ruta_csv = 'dataset/cleaned_dataset.csv'\n",
    "df = pd.read_csv(ruta_csv)\n",
    "\n",
    "# Mostrar información básica\n",
    "df.head(), df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b7ef2",
   "metadata": {},
   "source": [
    "## Paso 2: Crear subconjuntos con 20 datos de **entrenamiento** y 20 de **testeo**\n",
    "Seleccionaremos 40 muestras: 20 para entrenar y 20 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cce560c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 8), (20, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar 40 muestras aleatorias y dividir en 20/20\n",
    "df_40 = df.sample(n=40, random_state=42)\n",
    "X_small = df_40.drop('Outcome', axis=1)\n",
    "y_small = df_40['Outcome']\n",
    "\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(\n",
    "    X_small, y_small, train_size=20, test_size=20, random_state=42, stratify=y_small\n",
    ")\n",
    "\n",
    "X_train_small.shape, X_test_small.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1e8d1",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la función de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente fórmula matemática para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu función con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Embarazos | Glucosa | Presión Arterial | Grosor Piel | Insulina | IMC  | Función Hereditaria | Edad | Resultado |\n",
    "|-----------|---------|------------------|-------------|----------|------|---------------------|------|-----------|\n",
    "|     1     |   106   |        70        |      28     |   135    | 34.2 |        0.142        |  22  |     0     |\n",
    "|     2     |   102   |        86        |      36     |   120    | 45.5 |        0.127        |  23  |     1     |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu función sea el mismo.\n",
    "- La función debe imprimir el resultado del cálculo de la distancia euclidiana con los datos presentados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa56bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(29.172221307264213)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distancia_euclidiana(v1, v2):\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    return np.sqrt(np.sum((v1 - v2) ** 2))\n",
    "\n",
    "# Ejemplo rápido\n",
    "ejemplo = distancia_euclidiana(X_train_small.iloc[0], X_test_small.iloc[0])\n",
    "ejemplo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73bbcc",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN básico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu función de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos más cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu función a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Resultado` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d1223c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def knn_manual(X_train, y_train, X_test, k=3):\n",
    "    predicciones = []\n",
    "    for _, x_test in X_test.iterrows():\n",
    "        # Calcular distancias a todos los puntos de entrenamiento\n",
    "        distancias = [\n",
    "            (distancia_euclidiana(x_test, x_train), y)\n",
    "            for x_train, y in zip(X_train.values, y_train)\n",
    "        ]\n",
    "        # Ordenar por distancia y tomar los k vecinos\n",
    "        vecinos = sorted(distancias, key=lambda t: t[0])[:k]\n",
    "        etiquetas = [etq for _, etq in vecinos]\n",
    "        # Votación mayoritaria\n",
    "        pred = Counter(etiquetas).most_common(1)[0][0]\n",
    "        predicciones.append(pred)\n",
    "    return np.array(predicciones)\n",
    "\n",
    "pred_small = knn_manual(X_train_small, y_train_small, X_test_small, k=3)\n",
    "acc_small = accuracy_score(y_test_small, pred_small)\n",
    "acc_small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f7f05",
   "metadata": {},
   "source": [
    "## Paso 5: Usar toda la data con separación 80% entrenamiento / 20% testeo  \n",
    "\n",
    "### Pasos:\n",
    "1. Cargar todo el dataset.  \n",
    "2. Separar variables (X) y etiquetas (y).  \n",
    "3. Aplicar `train_test_split` con 80% para entrenamiento y 20% para testeo.  \n",
    "4. Mantener la proporción de clases usando estratificación.  \n",
    "5. Guardar los conjuntos de datos para usarlos en KNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e3b9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((313, 8), (79, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar variables y etiqueta\n",
    "y = df['Outcome']\n",
    "X = df.drop('Outcome', axis=1)\n",
    "\n",
    "# División 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb071d8",
   "metadata": {},
   "source": [
    "## Paso 6: Entrenar un KNN con los datos sin escalar (crudos) y calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Definir el valor de **k = 3** y el metodo **Euclidiano**.  \n",
    "2. Entrenar el modelo KNN con los datos crudos (sin normalizar/estandarizar).  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** comparando predicciones con etiquetas reales.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1842e010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.810126582278481"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN sin escalar\n",
    "knn_crudo = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_crudo.fit(X_train, y_train)\n",
    "\n",
    "pred_crudo = knn_crudo.predict(X_test)\n",
    "acc_crudo = accuracy_score(y_test, pred_crudo)\n",
    "acc_crudo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82664821",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **normalización Min-Max** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos normalizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32694423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7341772151898734"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalización Min-Max\n",
    "minmax = MinMaxScaler()\n",
    "X_train_norm = minmax.fit_transform(X_train)\n",
    "X_test_norm = minmax.transform(X_test)\n",
    "\n",
    "knn_norm = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_norm.fit(X_train_norm, y_train)\n",
    "\n",
    "pred_norm = knn_norm.predict(X_test_norm)\n",
    "acc_norm = accuracy_score(y_test, pred_norm)\n",
    "acc_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6519b",
   "metadata": {},
   "source": [
    "## Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **estandarización Z-score** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos estandarizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10afcc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7468354430379747"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estandarización Z-score\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "knn_std = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_std.fit(X_train_std, y_train)\n",
    "\n",
    "pred_std = knn_std.predict(X_test_std)\n",
    "acc_std = accuracy_score(y_test, pred_std)\n",
    "acc_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946086",
   "metadata": {},
   "source": [
    "## Paso 10/11: Tabla comparativa de accuracies  \n",
    "\n",
    "### Pasos:\n",
    "1. Reunir los resultados de accuracy de cada experimento:  \n",
    "   - KNN sin escalar (80/20).  \n",
    "   - KNN normalizado (80/20).  \n",
    "   - KNN estandarizado (80/20).  \n",
    "2. Crear una tabla con los resultados.  \n",
    "3. Comparar el desempeño de cada método.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e671386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experimento</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN crudo</td>\n",
       "      <td>0.810127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Min-Max</td>\n",
       "      <td>0.734177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Z-score</td>\n",
       "      <td>0.746835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experimento  Accuracy\n",
       "0    KNN crudo  0.810127\n",
       "1  KNN Min-Max  0.734177\n",
       "2  KNN Z-score  0.746835"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabla comparativa de accuracies\n",
    "import pandas as pd\n",
    "resultados = pd.DataFrame({\n",
    "    'Experimento': ['KNN crudo', 'KNN Min-Max', 'KNN Z-score'],\n",
    "    'Accuracy': [acc_crudo, acc_norm, acc_std]\n",
    "})\n",
    "resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cafd7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de reflexión y aplicación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bf383",
   "metadata": {},
   "source": [
    "### 1. ¿Por qué es importante normalizar o estandarizar los datos antes de usar KNN?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ee450",
   "metadata": {},
   "source": [
    "Es fundamental porque KNN es un algoritmo basado en distancias (como la distancia euclidiana). Si las variables tienen escalas muy diferentes, aquellas con valores numéricos más grandes dominarán el cálculo de la distancia, haciendo que el algoritmo ignore las variables con valores más pequeños."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393faba",
   "metadata": {},
   "source": [
    "### 2. ¿Qué diferencias observaste en el accuracy entre los datos crudos, normalizados y estandarizados?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6273f",
   "metadata": {},
   "source": [
    "Aunque la teoría sugiere escalar, es posible que en este caso particular (por la partición aleatoria de los datos o el tamaño del set de prueba de solo ~79 datos), las variables con mayor magnitud (como Glucosa o Insulina) fueran realmente las más predictivas y al escalarlas se perdió parte de esa señal fuerte, o simplemente fue un resultado fortuito de la aleatoriedad (random_state=42)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2743a4d",
   "metadata": {},
   "source": [
    "### 3. Si aumentamos el valor de **k** (número de vecinos), ¿cómo crees que cambiaría el rendimiento del modelo?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817198b3",
   "metadata": {},
   "source": [
    "**Reducción del ruido**: El modelo se vuelve menos sensible a \"outliers\" (datos atípicos) o ruido en los datos de entrenamiento, lo que generalmente suaviza la frontera de decisión.\n",
    "\n",
    "**Riesgo de Underfitting**: Si k es demasiado grande (ej. k=50), el modelo podría volverse demasiado simple y empezar a predecir siempre la clase mayoritaria, perdiendo detalles importantes de los patrones locales.\n",
    "\n",
    "**Conclusión**: Es probable que un valor ligeramente mayor (como k=5 o k=7) pudiera mantener o mejorar la estabilidad del modelo, pero un valor muy alto disminuiría el accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a02e07",
   "metadata": {},
   "source": [
    "### 4. ¿Qué ventaja tiene implementar KNN manualmente antes de usar scikit-learn?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b32f9",
   "metadata": {},
   "source": [
    "**Comprensión profunda**: Te permite entender exactamente cómo funciona el algoritmo \"bajo el capó\": cómo se calculan las distancias matemáticas entre puntos y cómo se realiza la votación mayoritaria.\n",
    "\n",
    "**Desmitificar la \"Caja Negra\"**: Al programarlo tú mismo, dejas de ver a KNeighborsClassifier como una herramienta mágica y entiendes la lógica matemática detrás de la predicción.\n",
    "\n",
    "**Depuración**: Ayuda a identificar por qué el modelo podría estar fallando en casos específicos al poder inspeccionar las distancias exactas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53e18",
   "metadata": {},
   "source": [
    "### 5. ¿Qué limitaciones presenta KNN cuando se aplica a conjuntos de datos grandes o con muchas dimensiones?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76827e64",
   "metadata": {},
   "source": [
    "**Costo Computacional (Lazy Learner)**: KNN no \"aprende\" un modelo durante el entrenamiento; memoriza los datos. Por ello, al momento de predecir, debe calcular la distancia contra todos los puntos de entrenamiento. En datasets grandes, esto es muy lento y costoso en memoria.\n",
    "\n",
    "**Maldición de la Dimensionalidad**: Cuando hay muchas variables (muchas dimensiones), todos los puntos tienden a estar \"lejos\" unos de otros, haciendo que la noción de \"vecino más cercano\" pierda sentido y la distancia euclidiana sea menos útil para distinguir clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707edf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c9c",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación: Práctica KNN\n",
    "\n",
    "| Criterio | Descripción | Puntaje Máximo |\n",
    "|----------|-------------|----------------|\n",
    "| **1. Carga y exploración del dataset** | Carga correcta del archivo CSV, explicación de las variables y verificación de datos. | 15 pts |\n",
    "| **2. Implementación manual de KNN** | Código propio para calcular distancias euclidianas, selección de vecinos y votación mayoritaria. | 20 pts |\n",
    "| **3. Predicción individual (ejemplo aleatorio)** | Explicación clara del proceso paso a paso para un ejemplo de test. | 10 pts |\n",
    "| **4. Uso de scikit-learn (KNN)** | Entrenamiento y evaluación con `train_test_split`, comparación con el método manual. | 15 pts |\n",
    "| **5. Normalización y estandarización** | Aplicación correcta de Min-Max y Z-score, con cálculo de accuracy en cada caso. | 20 pts |\n",
    "| **6. Tabla comparativa de accuracies** | Presentación clara de los resultados y comparación entre métodos. | 10 pts |\n",
    "| **7. Reflexión y preguntas finales** | Respuestas a las preguntas de análisis planteadas (profundidad y claridad). | 10 pts |\n",
    "\n",
    "**Total: 100 pts**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyda-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
